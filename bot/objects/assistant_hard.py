import logging
import typing as t

from pathlib import Path
from dataclasses import dataclass
from pydantic import BaseModel, Field

from llama_index.core import Settings, StorageContext, load_index_from_storage
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from llama_index.core.prompts import PromptTemplate
from llama_index.program.openai import OpenAIPydanticProgram


RAG_PROMPT = PromptTemplate("""
–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏ EORA. –¢–µ–±–µ –¥–∞–Ω –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å —Å–∞–π—Ç–∞).
–°—Ñ–æ—Ä–º–∏—Ä—É–π –∫—Ä–∞—Ç–∫–∏–π, —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç. –ó–∞—Ç–µ–º —Ä–∞–∑–±–µ–π –µ–≥–æ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∫–∞–∂–∏ —Å—Å—ã–ª–∫–∏
–Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ –∏—Ö URL.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤—ã–≤–æ–¥—É:
- –í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –ø–æ —Å—Ö–µ–º–µ (sentences[], sources[]).
- –í sources —É–∫–∞–∂–∏ —Ç–æ–ª—å–∫–æ —Ç–µ URL, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ —Å—Å—ã–ª–∞–µ—à—å—Å—è.
- –ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –î–û–õ–ñ–ù–û –∏–º–µ—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É —Å—Å—ã–ª–∫—É –≤ refs[].
- refs[] –¥–æ–ª–∂–Ω—ã –ø–æ–∫—Ä—ã–≤–∞—Ç—å –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –≤ sources[].
- –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –≤–≤–æ–¥–Ω—ã–º/–æ–±–æ–±—â–∞—é—â–∏–º, –≤—Å—ë —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤—å —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.
- –í sources[] —É–∫–∞–∂–∏ –≤—Å–µ URL, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å –≤ –æ—Ç–≤–µ—Ç–µ. –ù–µ –æ—Å—Ç–∞–≤–ª—è–π "–æ—Å–∏—Ä–æ—Ç–µ–≤—à–∏—Ö" –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
- –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π URL. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
- –ù–∞ –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –¥–∞–≤–∞–π —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã, –ø—Ä–∏ —ç—Ç–æ–º –±—É–¥—å –∫—Ä–∞—Ç–æ–∫ –∏ —Å—Ç–∞—Ä–∞–π—Å—è –æ–±—Ö–≤–∞—Ç–∏—Ç—å –≤–µ—Å—å —Å–ø–µ–∫—Ç—Ä –æ—Ç–≤–µ—Ç–æ–≤

–í–æ–ø—Ä–æ—Å:
{question}

–ö–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞):
{context}
""")



logger = logging.getLogger(__name__)


class Source(BaseModel):
    """–ï–¥–∏–Ω–∏—á–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –≤ –æ—Ç–≤–µ—Ç–µ (–ø—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ ID –∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º)."""
    id: int = Field(..., description="SLUG –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1)")
    url: str = Field(..., description="URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞")


class SentenceCite(BaseModel):
    """–û–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏ —Å–ø–∏—Å–æ–∫ ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —ç—Ç–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é."""
    sentence: str = Field(..., description="–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞")
    refs: list[int] = Field(default_factory=list, description="ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1)")


class AnswerPayload(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è + —Ä–µ–µ—Å—Ç—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (ID -> URL)."""
    sentences: list[SentenceCite]
    sources: list[Source]


@dataclass
class Assistant:
    persist_dir: Path
    system_prompt: t.Optional[str]

    model: str = "gpt-4o-mini"
    embed_model: str = "text-embedding-3-small"
    similarity_top_k: int = 4
    temperature: float = 0.7

    def __post_init__(self) -> None:
        # —Å–æ–∑–¥–∞—ë–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
        llm_kwargs: dict[str, t.Any] = {"model": self.model, "temperature": self.temperature}
        Settings.embed_model = OpenAIEmbedding(model=self.embed_model)

        # –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
        storage_ctx = StorageContext.from_defaults(persist_dir=str(self.persist_dir))
        self._index = load_index_from_storage(storage_ctx)
        self._retriever = self._index.as_retriever(similarity_top_k=self.similarity_top_k)

        #  –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–≥–æ JSON –ø–æ –Ω–∞—à–µ–π —Å—Ö–µ–º–µ
        self._program = OpenAIPydanticProgram(
            tool_choice='auto',
            output_cls=AnswerPayload,
            prompt=PromptTemplate(self.system_prompt),
            llm=OpenAI(**llm_kwargs),
        )

    # —Å–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
    def _build_context(self, question: str) -> str:
        nodes = self._retriever.retrieve(question)
        chunks: list[str] = []
        for n in nodes:
            # —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–∞
            chunks.append(n.get_content())
            url = n.metadata.get("url")
            if url:
                chunks.append(f"[URL] {url}")
        return "\n\n---\n\n".join(chunks)

    def answer_json(self, question: str) -> AnswerPayload:
        context = self._build_context(question)
        payload: AnswerPayload = self._program(
            question=question,
            context=context,
        )
        return payload

    def answer_text(self, question: str) -> str:
        payload = self.answer_json(question)

        # —Å–æ–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç. –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ + —Å—Å—ã–ª–∫–∏
        parts: list[str] = []
        source_dict = {source.id: source.url for source in payload.sources}

        for s in payload.sentences:
            suffix = (" " + "".join(f'[<a href="{source_dict.get(i)}">{i}</a>]' for i in s.refs)) if s.refs else ""
            parts.append(s.sentence.rstrip() + suffix)

        text = " ".join(parts).strip()

        if not text:
            return 'ü§∑ –ù–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å. –ü–æ–ø—Ä–æ–±—É–π —Å–ø—Ä–æ—Å–∏—Ç—å –µ—â—ë —Ä–∞–∑'

        return text





