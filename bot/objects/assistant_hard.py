import logging
import typing as t

from pathlib import Path
from dataclasses import dataclass
from pydantic import BaseModel, Field

from llama_index.core import Settings, StorageContext, load_index_from_storage
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from llama_index.core.prompts import PromptTemplate
from llama_index.program.openai import OpenAIPydanticProgram



logger = logging.getLogger(__name__)


class Source(BaseModel):
    """–ï–¥–∏–Ω–∏—á–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –≤ –æ—Ç–≤–µ—Ç–µ (–ø—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ ID –∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º)."""
    id: int = Field(..., description="ID –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1)")
    url: str = Field(..., description="URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞")


class SentenceCite(BaseModel):
    """–û–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏ —Å–ø–∏—Å–æ–∫ ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —ç—Ç–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é."""
    sentence: str = Field(..., description="–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞")
    refs: list[int] = Field(default_factory=list, description="ID –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1)")


class AnswerPayload(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è + —Ä–µ–µ—Å—Ç—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (ID -> URL)."""
    sentences: list[SentenceCite]
    sources: list[Source]


@dataclass
class Assistant:
    persist_dir: Path
    system_prompt: t.Optional[str]

    model: str = "gpt-4o-mini"
    embed_model: str = "text-embedding-3-small"
    similarity_top_k: int = 4
    temperature: float = 0.7

    def __post_init__(self) -> None:
        # —Å–æ–∑–¥–∞—ë–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
        llm_kwargs: dict[str, t.Any] = {"model": self.model, "temperature": self.temperature}
        Settings.embed_model = OpenAIEmbedding(model=self.embed_model)

        # –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
        storage_ctx = StorageContext.from_defaults(persist_dir=str(self.persist_dir))
        self._index = load_index_from_storage(storage_ctx)
        self._retriever = self._index.as_retriever(similarity_top_k=self.similarity_top_k)

        #  –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–≥–æ JSON –ø–æ –Ω–∞—à–µ–π —Å—Ö–µ–º–µ
        self._program = OpenAIPydanticProgram(
            tool_choice='required',
            output_cls=AnswerPayload,
            prompt=PromptTemplate(self.system_prompt),
            llm=OpenAI(**llm_kwargs),
        )

    # —Å–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
    def _build_context(self, question: str) -> str:
        nodes = self._retriever.retrieve(question)
        chunks: list[str] = []
        for n in nodes:
            # —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–∞
            chunks.append(n.get_content())
            url = n.metadata.get("url")
            if url:
                chunks.append(f"[URL] {url}")
        return "\n\n---\n\n".join(chunks)

    def answer_json(self, question: str) -> AnswerPayload:
        context = self._build_context(question)
        payload: AnswerPayload = self._program(
            question=question,
            context=context,
        )
        return payload

    def answer_text(self, question: str) -> str:
        payload = self.answer_json(question)

        # —Å–æ–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç. –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ + —Å—Å—ã–ª–∫–∏
        parts: list[str] = []
        source_dict = {source.id: source.url for source in payload.sources}

        for s in payload.sentences:
            suffix = (" " + "".join(f'[<a href="{source_dict.get(i)}">{i}</a>]' for i in s.refs)) if s.refs else ""
            parts.append(s.sentence.rstrip() + suffix)

        text = " ".join(parts).strip()

        if not text:
            return 'ü§∑ –ù–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å. –ü–æ–ø—Ä–æ–±—É–π —Å–ø—Ä–æ—Å–∏—Ç—å –µ—â—ë —Ä–∞–∑'

        return text





